
- AlpacaEval-LC (24.04): [Length-Controlled AlpacaEval: A Simple Way to Debias Automatic Evaluators](https://arxiv.org/pdf/2404.04475)
- Chatbot Arena (24.03): [Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](https://arxiv.org/pdf/2403.04132)
- RLHF Long way to go (23.10): [A Long Way to Go: Investigating Length Correlations in RLHF](https://arxiv.org/pdf/2310.03716)
- AlpacaFarm (23.05): [AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback](https://arxiv.org/pdf/2305.14387)
- RLHF DPO (23.05): [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/pdf/2305.18290)
- Chinchilla (22.03): [Training Compute-Optimal Large Language Models](https://arxiv.org/pdf/2203.15556)
- RLHF PPO (22.03): [Training language models to follow instructions with human feedback](https://arxiv.org/pdf/2203.02155)
- Scaling Laws (20.01): [Scaling Laws for Neural Language Models](https://arxiv.org/pdf/2001.08361/1000)
